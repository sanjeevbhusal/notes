{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJZcdRF3Didy"
   },
   "source": [
    "# Data Quality Inspection and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVUHcyPao4Wo"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "In this reading assignment you’ll be able to:\n",
    "\n",
    "* Describe why data quality is relevent,\n",
    "* Inspect data quality using data profiling and Visualisation,\n",
    "\n",
    "* Find three common probelms that a machine learning engineer faces while cleaning  the data,\n",
    "\n",
    "* Explain why data Monitoring and Version Control is necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yrd8IDU1DkOb"
   },
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqSldToPKiUC"
   },
   "source": [
    "Data quality is the absence of intolerable defects. It is not the absence of defects.\n",
    "Every organization will have defects in data. It is the absence of defects that would have real, measurable negative business\n",
    "impact.[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBTAIgljN74L"
   },
   "source": [
    "## Why Data Quality is Relevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiSg6MwQDrUo"
   },
   "source": [
    "__\"Data-intensive projects have a single point of failure: data quality.\"- [George Krasadakis, Data Quality in the era of A.I.](https://www.freecodecamp.org/news/data-quality-in-the-era-of-a-i-d8e398a91bef/)__ \n",
    "\n",
    "\n",
    "A machine learning algorithm discovers a pattern in data and successfully predicts the given data's output value without explicit programming. Hence, data is vital for machine learning. To train a predictive model, first, data must be right. It should be unbiased with the correct level.\n",
    "The quality of data used in a machine learning project will inevitably impact project success even though the business objective is clear.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__\"If Your Data Is Bad, Your Machine Learning Tools Are Useless.\" - [ Thomas C. Redman](https://hbr.org/search?term=thomas%20c.%20redman)__\n",
    "\n",
    "In another article on Harvard Business Review [ Thomas C. Redman](https://hbr.org/search?term=thomas%20c.%20redman) states, \"[Bad Data Costs the U.S. $3 Trillion Per Year.](https://hbr.org/2016/09/bad-data-costs-the-u-s-3-trillion-per-year)\" Therefore data quality is a crucial aspect of machine learning. Now let's discuss how to recognize high-quality data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L7FKkntozON"
   },
   "source": [
    "## What is high-quality data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pD2XpFro3nf"
   },
   "source": [
    "\"Data is high quality if it is fit for [its] intended uses in operations, decision making, and planning. Data is deemed of high quality if it correctly represents the real-world construct to which it refers.\"- [Wikipedia](https://en.wikipedia.org/wiki/Data_quality)\n",
    "\n",
    "\n",
    "* It means quality data should reflect the logic of the business process or meet the needs of customers.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze3w7mKHebf2"
   },
   "source": [
    "## What are the features of high quality data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7LbF737eiB-"
   },
   "source": [
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1UfJSGy_o5nN7uuwJk05oJlh9jzWjPe40' height=500/>\n",
    "<Figcaption>Figure 1: Features of High quality data </Figcaption>\n",
    "</center>\n",
    "</image>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOfwQ4jceuEx"
   },
   "source": [
    "\n",
    "* Accurate:\n",
    "    * Accuracy implies that the data represents a real-world entity the same as the one that should have been represented.\n",
    "\n",
    "* Complete:\n",
    "    * Completeness is the ability of data to represent every\n",
    "meaningful state of the real-world entity. Completeness refers to the completeness of the information set available to support a user's needs.  For example, if one channel is missing in an RGB image, it cannot show the real color; the image is incomplete.\n",
    "\n",
    "* Consistent:\n",
    "    * Consistency refers to the consistent representation and interpretation of data across\n",
    "repositories, tables. Data is consistent if it doesn't violate semantic rules defined\n",
    "over (a set of) data items, where items can be tuples of relational tables or records in a file. For example, the Integrity constraint MYSQL database.\n",
    "\n",
    "\n",
    "* Timely:\n",
    "    * A timely data represents the reality (change of the real-world state) from the required point in time. Outdated data can be worse than no data. \n",
    "\n",
    "\n",
    "* Reliable:\n",
    "    *  Reliability indicates the correctness of data. In reliability, you measure \"whether the data can be counted on to convey the\n",
    "the right information.\" \n",
    "\n",
    "* Valuable:\n",
    "    * Data should add value to the business.\n",
    "* Interpretable:\n",
    "    * Data should be interpretable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_eutGgIOxjV"
   },
   "source": [
    "## Types of Data\n",
    "\n",
    "\n",
    "Data represent the real-world entity in a format that can be stored, retrieved,\n",
    "and used by a software application and communicated through a network. Therefore data may be structured or unstructured.\n",
    "\n",
    "1. Structured, when each data element has an associated fixed structure. Example: Relational database or tabular data are the most popular type of structured data.\n",
    "\n",
    "2. Unstructured, when data are expressed in natural language, no specific\n",
    "structure or domain types are defined. Example: text data, images, and videos.\n",
    "\n",
    "In this reading assignment, we will first discuss data quality inspection in structured tabular data, and then we will discuss data quality inspection in unstructured data, mostly text, and Images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxn9WoZ8p16_"
   },
   "source": [
    "## How do you inspect the quality of the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eF1OERWMA5A"
   },
   "source": [
    "\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1fAf0P-6UfhF8mvdXUwc1Amhpv12O3h7o' height=500/>\n",
    "<Figcaption>Figure 2: Methods of Data Quality Inspection</Figcaption>\n",
    "</center>\n",
    "</image>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPKzT3dHfd4O"
   },
   "source": [
    "The two common approach of data quality inspection is: Data Profiling and Data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ve0Khd-JPjo2"
   },
   "source": [
    "### Data Profiling\n",
    "\n",
    "Data profiling is a process of analyzing, understanding content, and interrelationships on the raw data to characterize the information embedded within a data set. Data profiling collects statistics and meta-information about available data that provide insight into the content of data sets.\n",
    "\n",
    "Data profiling utilizes methods of descriptive statistics.\n",
    "Descriptive statistics include those that summarize the central tendency, dispersion, and shape of a dataset’s distribution, excluding NaN(not a number) values. You can use the results of data profiling to formulate a hypothesis about the data features.\n",
    "\n",
    "In data science, you can find the descriptive statistics of your dataset using  Pandas [dataframe.describe()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhwYnqgNMMCw"
   },
   "source": [
    "In data profiling for a numerical column, you can find:\n",
    "\n",
    "1. Count:\n",
    "    * Count is the number of non-missing data points for each variable.\n",
    "\n",
    "2. Mean:\n",
    "    * Mean is average. The calculation of the mean incorporates all values in the data. Suppose you change one value, then the average value changes. In a normal distribution, the average represents the center of data points. However, It doesn't happen in a skewed distribution.  \n",
    "\n",
    "3. Standard deviation(Std):\n",
    "    * Standard deviation tells you how spread out the data is. It is a measure of how far each observed value is from the mean. In any distribution, about 95% of values will be within two standard deviations of the mean.\n",
    "4. Minimum value(min):\n",
    "    * Min is the minimum value in a column.\n",
    "5. Percentile:\n",
    "    * Percentile is a number where a certain percentage of scores fall below that number. \n",
    "6. Maximum value (max):\n",
    "    * Max is the extreme or maximum value in a column.\n",
    "\n",
    "You can also find mode, frequency, and other metadata information like data type, unique values, etc. that describes the data. You can represent all these statistics in the graph, which I will discuss in data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FD_nZdWtKeH2"
   },
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESrBd2TGi55F"
   },
   "source": [
    "Reading each row and columns of tabular data and trying to understand it is infeasible. You can extract knowledge from the data and present it to any audience using data visualization.\n",
    "\n",
    "Data visualization is the graphical representation of information in the data by using charts, graphs, etc.  \n",
    "This chapter will focus on different types of graphs and charts that a machine learning engineer uses to visualize data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9WMtcsfJ846"
   },
   "source": [
    "### Bar Plot\n",
    "\n",
    "The bar plot shows the relationship between a numeric and a categoric variable. In the bar plot, the categorical variable is represented as a bar, and the size of the bar represents its numeric value.\n",
    "\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1X2MWCIsxCI0sUp_C0lK-Oa2lVHbgtfiX'/>\n",
    "<figcaption> Figure : Bar Plot </figcaption>\n",
    "</center>\n",
    "</image>\n",
    "\n",
    "The above figure shows run scores by group and gender. In the group, `G1`  men scored 30, and females scored 35 runs. Similarly, you can interpret the values in the bar chart. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-Ad5wu6KC0E"
   },
   "source": [
    "### Histogram\n",
    "\n",
    "A histogram is a representation of the distribution of numerical data that gives a discretized display of value frequency.\n",
    "The data points are split into discrete, evenly spaced bins, and the number of data\n",
    "points in each bin are plotted. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1jS0t_0_w_FV_yT4sjAc7Yt5gAg_Wnwtj' />\n",
    "<figcaption> Figure : Histogram of Price column</figcaption>\n",
    "</center>\n",
    "</image>\n",
    "\n",
    "In the above figure, the histogram contains the frequency distribution of the `price($1000s)` column. Most of the price value lies in between approx `17` to `25` thousand. Price Values between `40-50` are outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nzi8nUimKrln"
   },
   "source": [
    "### Boxplot\n",
    "\n",
    "Boxplots are a standardized way of displaying the distribution of data based on a five number summary: `minimum`, `first quartile (Q1)`, `median(Q2)`, `third quartile (Q3)`, and `maximum.`\n",
    "\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1HA6nFmliLI57NT1Qrv-CVE3TT78bbwQo'/>\n",
    "<figcaption> Figure : Boxplot</figcaption>\n",
    "</center>\n",
    "</image>\n",
    "\n",
    "In the above figure green color points are outliers. Most of the value lies inside interquartile range(IQR). Median is a middle value which is given by Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW1mAsotLNSN"
   },
   "source": [
    "### Scatter Plot\n",
    "A scatterplot shows the relationship between two numerical variables. \n",
    "For example, following scatterplot shows the  `price`and on x-axis and `LSTAT` is on y-axis:\n",
    "\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1XP4uulPz5E3SrLxXQ6ZOGXMsBwsHvoQD'/>\n",
    "<figcaption> Figure : Scatterplot </figcaption>\n",
    "</center>\n",
    "</image>\n",
    "\n",
    "Scatterplot describes the correlation between the two variables. In the above figure, as `price` increases, the value of `LSTAT` decreases. It means `price` and `LSTAT` are negatively correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxLZ2LA-Le62"
   },
   "source": [
    "### Heatmap\n",
    "A heatmap is a 2D graphical representation of data where the individual values that are contained in a matrix are represented as colors. The following diagram is a heatmap of correlation between the variables.\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1PoCcONDi6WWrLYqVwxUQ-jSV8RHzlT2O'/>\n",
    "<figcaption> Figure : Heatmap</figcaption>\n",
    "</center>\n",
    "</image>\n",
    "\n",
    "In the above heatmap, all diagonal value is one. It's because the correlation between two identical variables is one.\n",
    "The `LSTAT` and the price column has a -0.74 value of correlation. It is a negative correlation. `TAX` and `RAD` column is positively correlated, and their value of correlation is 0.91. The takeaway of this heatmap is that you cannot use`TAX` and `RAD` as the independent variable in the linear regression problem because it violates the linear regression assumption. Linear regression assumes that the independent variable should not be highly correlated. \n",
    "You should drop one column, either `TAX` or `RAD.` The dropped column is irrelevant. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gBMsstkMPeZ"
   },
   "source": [
    "There are other visualization tools like:\n",
    "* [Violin plot](https://seaborn.pydata.org/generated/seaborn.violinplot.html),\n",
    "* [Joint plot](https://seaborn.pydata.org/generated/seaborn.jointplot.html), etc.\n",
    "\n",
    "\n",
    "You can apply them according to your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kOYYBW2NtXy"
   },
   "source": [
    "## Data Cleaning Process\n",
    "\n",
    "The first step to data cleaning is to identify impurity in your dataset. Impurities creates cleaning problems in the dattaset.  Some Common Cleaning Problems are:\n",
    "\n",
    "* Irrelevant data\n",
    "* Parsing and Type Conversions\n",
    "* Structural Errors (check for typos and mislabeled classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NzXhzD2OleY"
   },
   "source": [
    "### __Irrelevant feature__\n",
    "\n",
    "As I have already shown you in heatmap either `TAX` or `RAD` becomes irrelevant because there is no point in using two independent correlated features because it will just increase computation time and adds no significant impact on model performance.An example is linear regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nEIG1kvY2dd"
   },
   "source": [
    "There is another problem you will face so called parsing and type conversion. Your dataset may contains datetime features. Using datetime column you can extract other features which is called parsing. Type conversion problem is just datatype conversion problem. Let's discuss parsing and type conversion on  the new exmaple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aJhoc_qhb4D"
   },
   "source": [
    "### __Parsing and Type Conversions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2QvJ5jbhd3b"
   },
   "source": [
    "Suppose a King's garage buys used Ford's cars and sells it to other customers. King's garage wants to predict how much a car will cost for them when they buy it form owners. \n",
    "Column details:\n",
    "* purchase_date: Date of purchase of new car \n",
    "* sold_date: Date of car sold in King's garage\n",
    "* model: Car's model name\n",
    "* car_class: Class of cars\n",
    "* Price in dollars: Cost price of King's garage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BvZ2lzHjqHrL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "car = {\n",
    "    \"purchase_date\":['2016-04-16','2015-11-21','2015-07-06','2018-12-02'],\n",
    "    \"sold_date\": ['2018-05-22','2017-09-18','2016-01-01','2019-08-04'],\n",
    "    \"model\":['e-series', 'mustang', 'mustang' , 'E-SERIES'],\n",
    "    \"car_class\":['third','first',1,'first'],\n",
    "    \"Price in dollars\":[3495.0,4217.0,5000.0,4225.0]\n",
    "\n",
    "}\n",
    "df_ = pd.DataFrame(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dVW71ONuAB72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>sold_date</th>\n",
       "      <th>model</th>\n",
       "      <th>car_class</th>\n",
       "      <th>Price in dollars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>e-series</td>\n",
       "      <td>third</td>\n",
       "      <td>3495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-21</td>\n",
       "      <td>2017-09-18</td>\n",
       "      <td>mustang</td>\n",
       "      <td>first</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>mustang</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-02</td>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>E-SERIES</td>\n",
       "      <td>first</td>\n",
       "      <td>4225.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  purchase_date   sold_date     model car_class  Price in dollars\n",
       "0    2016-04-16  2018-05-22  e-series     third            3495.0\n",
       "1    2015-11-21  2017-09-18   mustang     first            4217.0\n",
       "2    2015-07-06  2016-01-01   mustang         1            5000.0\n",
       "3    2018-12-02  2019-08-04  E-SERIES     first            4225.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rKD8Jb1iWtml"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "purchase_date        object\n",
       "sold_date            object\n",
       "model                object\n",
       "car_class            object\n",
       "Price in dollars    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Th5sLYanb0k"
   },
   "source": [
    "__Type Conversion__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTl-QooYADgi"
   },
   "source": [
    "In the given data set `Price in dollars` Column has all integer value. However, datatype of this column is float type. Therefore, you need to convert it into integer using pandas [astype()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulPRLycDnlg4"
   },
   "source": [
    "\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1XeL-x5fsnVwXLIziT1TEyQ3a5izEQvCM' />\n",
    "\n",
    "</center>\n",
    "</image>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XYDNrkIg_hhr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>sold_date</th>\n",
       "      <th>model</th>\n",
       "      <th>car_class</th>\n",
       "      <th>Price in dollars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>e-series</td>\n",
       "      <td>third</td>\n",
       "      <td>3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-21</td>\n",
       "      <td>2017-09-18</td>\n",
       "      <td>mustang</td>\n",
       "      <td>first</td>\n",
       "      <td>4217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>mustang</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-02</td>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>E-SERIES</td>\n",
       "      <td>first</td>\n",
       "      <td>4225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  purchase_date   sold_date     model car_class  Price in dollars\n",
       "0    2016-04-16  2018-05-22  e-series     third              3495\n",
       "1    2015-11-21  2017-09-18   mustang     first              4217\n",
       "2    2015-07-06  2016-01-01   mustang         1              5000\n",
       "3    2018-12-02  2019-08-04  E-SERIES     first              4225"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['Price in dollars'] = df_['Price in dollars'].astype('int')\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tq2fSoIgWgMI"
   },
   "source": [
    "__Parsing__\n",
    "\n",
    "\n",
    "In this section, you will see examples of DateTime parsing. Using DateTime data, you will calculate days of car used.\n",
    "\n",
    "* Parsing is mostly used in Web scraping to clean HTML DOM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5YSY0Vk7E5I"
   },
   "source": [
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1aN2P41W47zwnVBzZFWHgV8pfQ-IuQXGw' />\n",
    "\n",
    "</center>\n",
    "</image>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cS5dOKD1Xx1h"
   },
   "source": [
    "_The column `purchase_date` and `sold_date` has object datatype; however, it should be in DateTime format. Let's type convert object type dates to DateTime format/datatype._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q2mvJUex_mUy"
   },
   "outputs": [],
   "source": [
    "df_['purchase_date'] = pd.to_datetime(df_['purchase_date'], format =\"%Y-%m-%d\") \n",
    "df_['sold_date'] = pd.to_datetime(df_['sold_date'], format =\"%Y-%m-%d\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y9f1F5p-Ydda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "purchase_date       datetime64[ns]\n",
       "sold_date           datetime64[ns]\n",
       "model                       object\n",
       "car_class                   object\n",
       "Price in dollars             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4AhNU6JYhWu"
   },
   "source": [
    "_Let's calculate how many days the owner used his car and went to sell it to King's garage._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AbRnfejjYgOG"
   },
   "outputs": [],
   "source": [
    "df_['used days'] = (df_['sold_date'] - df_['purchase_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aCNT4rHmLwnC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>sold_date</th>\n",
       "      <th>model</th>\n",
       "      <th>car_class</th>\n",
       "      <th>Price in dollars</th>\n",
       "      <th>used days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>e-series</td>\n",
       "      <td>third</td>\n",
       "      <td>3495</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-21</td>\n",
       "      <td>2017-09-18</td>\n",
       "      <td>mustang</td>\n",
       "      <td>first</td>\n",
       "      <td>4217</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>mustang</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-02</td>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>E-SERIES</td>\n",
       "      <td>first</td>\n",
       "      <td>4225</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  purchase_date  sold_date     model car_class  Price in dollars  used days\n",
       "0    2016-04-16 2018-05-22  e-series     third              3495        766\n",
       "1    2015-11-21 2017-09-18   mustang     first              4217        667\n",
       "2    2015-07-06 2016-01-01   mustang         1              5000        179\n",
       "3    2018-12-02 2019-08-04  E-SERIES     first              4225        245"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dz7TIiSgQ62"
   },
   "source": [
    "### __Structural Errors__\n",
    "\n",
    "\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1Vgn_F-no0OwUu_IOsR9l-YRJTeDS4I-f' />\n",
    "<Figcaption>Figure 2: Structural Errors in Data </Figcaption>\n",
    "</center>\n",
    "</image>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opnCQqvrM-jA"
   },
   "source": [
    "\n",
    "__Inconsistent Capitalization__\n",
    "\n",
    "* In the column model, the e-series is in uppercase and lowercase both. It would be best if you made it consistent because while encoding this data, the encoder will take the lowercase and uppercase word as a different entity. Consistent means either lowercase or in uppercase. In our case, I will make it lowercase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFYNF6pkozuW"
   },
   "source": [
    "\n",
    "\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1iJqYPParauXfy763Ft_DPfHvZsQCDqUg' />\n",
    "\n",
    "</center>\n",
    "</image>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfGTx3qur3ej"
   },
   "source": [
    "_Let's solve inconsistent capitalization problem._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK3AZfIE_t9j"
   },
   "outputs": [],
   "source": [
    "df_.model = [x.lower() for x in df_['model']]\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_Ouk_NcoPCs"
   },
   "source": [
    "\n",
    "__Mislabeled Classes__\n",
    "\n",
    "* The second problem of structural error is the mislabeled class. In the column `car_class,` you will see the use of number 1 and first. One and first is logically same. You can label this correctly by replacing 1 with first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPK6E_CpoQfh"
   },
   "source": [
    "\n",
    "<image>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1Qp_KyCXLih3ExOoPqBST-w6_QukvKwGo' />\n",
    "\n",
    "</center>\n",
    "</image>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcrbHKjxsFsg"
   },
   "source": [
    "_Let's Solve Mislabeled class problem._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eI1QpXGs_uBp"
   },
   "outputs": [],
   "source": [
    "df_.car_class.replace(1, 'first', inplace = True)\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bnSIjHps0aN"
   },
   "source": [
    " Now let's discss about quality inspection in unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztx-NqSKyV7q"
   },
   "source": [
    "## Data quality Inspection and Cleaning in Unstructured Data.\n",
    "\n",
    "You have already learned about different data quality inspection and cleaning in tabular data. The question now comes into mind about non-tabular data, for example, text and images. In this section, I will give you some insights about data quality issues in text and Images.\n",
    "\n",
    "\n",
    "__Data quality inspection on Images__\n",
    "\n",
    "Low-quality images are an unavoidable reality for many real-world computer vision applications.  They can be life-threatening at an extreme level, limiting autonomous vehicles and traffic controllers to safely navigate their surroundings. Therefore it is essential to measure the quality of images. Image Quality Assessment is a challenging task yet highly important.\n",
    "You can inspect image quality using:\n",
    "\n",
    "1. Hosaka Plot:\n",
    "    * Hosaka Plot used to evaluate the quality of a compressed image. \n",
    "\n",
    "2. Histogram:\n",
    "    * Since histograms contain cumulated information of the image grey value histogram measure gives a global impression of the image quality by considering statistically relevant effects. \n",
    "\n",
    "\n",
    "\n",
    "__Data quality inspection on Text__\n",
    "\n",
    "Text data mostly come from social media or the web. Therefore can occur with `HTML` tags or with `XML` tags. \n",
    "Some problems that text data might have are:\n",
    "\n",
    "* Misspelling \n",
    "* Random white spaces in-between words\n",
    "* HTML tags, XML tags and special character.\n",
    "\n",
    "All these problems are inspected and solved using the NLTK library, \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94zz_hJFlXjc"
   },
   "source": [
    "After the inspection, you will know the different issues it has, and you solve it. It requires data versioning and monitoring. Let's discuss them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lET7bFdaZqT0"
   },
   "source": [
    "## Data Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0czqqq5_ZvwS"
   },
   "source": [
    "The basic idea of data versioning is that, as you work, you create static copies of your work so that you can refer it back.\n",
    "\n",
    "<center> Table 1: Sentiment analysis data(raw)</center>\n",
    "\n",
    "| Sentiment| Message|\n",
    "|----| ---|\n",
    "|Happy|  \\\\\\r May all the love you gave to us come back to you a hundredfold on this special day! |\n",
    "|Happy| \\\\\\n Summer will end  soon enough Hurrey <:)|\n",
    "|Sad| #Bad_day \\n Some days are just bad, that's all. |\n",
    "\n",
    "\n",
    " For example, You have raw data of sentiment analysis. After getting that data, you preprocess it and clean it. The preprocessing step may include the removal of a special character using Regex. It is a static copy of your data. Let's say it is version one(v1). \n",
    "\n",
    "<center> Table 2: Sentiment analysis data(v1)</center>\n",
    "\n",
    "| Sentiment| Message|\n",
    "|----| ---|\n",
    "|Happy| may all the love you gave to us come back to you a hundredfold on this special day |\n",
    "|Happy|summer will end soon enough hurrey|\n",
    "|Sad| bad day some days are just bad that's all |\n",
    "\n",
    "\n",
    "\n",
    "The `Sentiment analysis data(v1)` is particularly important when working in a team because it aids in reproducibility; there is no point to preprocess data again.  However, sharing of processed data which changes often makes no sense. Therefore, it is preferable to share raw data and the scripts and notebooks that transform raw into the processed data. The idea that you should version your data is somewhat controversial.\n",
    "\n",
    "Suppose you built the sentiment analysis model using the pre-processed table 1 dataset. After some months, you collected additional data. You can either use newly collected data to create a model or use combined data to create a model. Data changes over time; therefore, data versioning is used. Data versioning is used to keep track of the collected dataset at a different time. It is somewhat similar to git, which is used to track changes in any set of files during software development.\n",
    "\n",
    "Some open source data version control system are: DVC, MLflow, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Note the exciting point. Here raw data represents ground reality; however, preprocessed data don't.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlluV77S9CRM"
   },
   "source": [
    "\n",
    "__When should you version your data?__\n",
    "\n",
    "* When making metadata changes, like adding or deleting columns or changing the datatype.\n",
    "\n",
    "* When you're training experimental machine learning models. You can apply a different version of your data and test its performance on the model. \n",
    "\n",
    "\n",
    "__When should you consider not versioning your data?__\n",
    "\n",
    "* If your data is large enough that storing a versioned copy would be expensive.\n",
    "\n",
    "* If you are version controlling your code in git hub. Git hub doesn't support large files. You can use [GitLFS ](https://git-lfs.github.com/) in this case, but in general, it is not recommended.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saqzv0K7t7ve"
   },
   "source": [
    "## Data monitoring\n",
    "\n",
    "Data monitoring is the process of actively correcting and judging your data and its quality to ensure that it fits for purpose. \n",
    "\n",
    "To monitor data, you must specify data quality metrics or criteria tied to specific business objectives.  After establishing the preliminaries, you can compare the results over time, allowing for your data improvement.\n",
    "\n",
    "\n",
    "\n",
    "__Benefits of data monitoring:__\n",
    "\n",
    "1. Data monitoring helps you to identify the problem that is observed using different versions of data.\n",
    "\n",
    "2. Data monitoring helps you to identify where you should focus your data quality initiatives.\n",
    "\n",
    "3. Data monitoring helps you verify data fields for completeness, uniqueness, statistical anomalies, and more. \n",
    "\n",
    "4. Data monitoring helps you to visualize fluctuations in data quality levels over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFY-zOnPjVFO"
   },
   "source": [
    "## Key Take-Aways\n",
    "* High-quality data beats fancy algorithms.\n",
    "\n",
    "* Data profiling and visualization are used to check the quality of data. Note: This is not the only step to observe data quality. \n",
    "\n",
    "* Some common data cleaning problems are:\n",
    "\n",
    "    * Irrelevant/inconsistent data\n",
    "    * Parsing and Type Conversions\n",
    "    * Structural Errors (check for typos and mislabeled classes)\n",
    "\n",
    "* Irrelevant data is dropped while inconsistent data is made consistent.\n",
    "\n",
    "* Parsing is mostly used in DateTime data handling and web scraping to clean HTML DOM.\n",
    "* Structural data are inconsistent data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6hyXv9rFrtO"
   },
   "source": [
    "# References\n",
    "\n",
    "[1] Cai, L. and Zhu, Y., 2015. The Challenges of Data Quality and Data Quality Assessment in the Big Data Era. Data Science Journal, 14, p.2. DOI: [http://doi.org/10.5334/dsj-2015-002](http://doi.org/10.5334/dsj-2015-002)\n",
    "\n",
    "[2] McKnight, W. (2013). Information management: strategies for gaining a competitive advantage with data. Newnes.\n",
    "\n",
    "[3] Olson, J. E. (2003). Data quality: the accuracy dimension. Elsevier.\n",
    "\n",
    "* Read page number: 3-4 and 9-13.\n",
    "\n",
    "[4] Sadiq, S. (Ed.). (2013). Handbook of data quality: Research and practice. Springer Science & Business Media.\n",
    "* Read page number: 18-24.\n",
    "\n",
    "\n",
    "\n",
    "[5] [Data quality Wikipedia](https://en.wikipedia.org/wiki/Data_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeHgqVYQVh7x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Read: Data Quality Inspection and Data Cleaning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
